{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Jeff-AB/ECE542FinalProject/blob/jeff-development/ECE542FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNtCvd6KxZO0"
   },
   "source": [
    "# ECE 542 Final Project\n",
    "\n",
    "## How to Develop Code for the ECE 542 Final Project\n",
    "We will be using jupyter notebooks and Google Codelabs to develop our image segmentation application. Each user will work from the same notebook using branches. Here is our strategy to use branches.\n",
    "\n",
    "1.   Create a public github account(not a NCSU account). Request an invite to the repository from Jeff, and you will receive an email at the account linked to your github with an access link.\n",
    "\n",
    "2.   Perform the following command to create a local repository on your computer\n",
    "\n",
    "## Upload Rules\n",
    "Upload your changes to your branch only. When you think that your changes are sufficient, make a pull request to the master branch from your personal branch and assign other members to review it. After a branch has been merged, everyone has to update their setups with the new master branch. You will be notified of this in the slack channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Settings\n",
    "This section is used to put the notebook in Colab or local machine mode. It defines paths for each and optionally loads the zip file with the raw data if it does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28288,
     "status": "ok",
     "timestamp": 1585533817171,
     "user": {
      "displayName": "Jeffrey Barahona",
      "photoUrl": "",
      "userId": "05714273706173763154"
     },
     "user_tz": 240
    },
    "id": "hscjYpi8cktA",
    "outputId": "e5496835-e80b-4ed8-f2a8-9fedf45a6cee"
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import sys\n",
    "\n",
    "\n",
    "# Google Colab or Local Notebook Settings\n",
    "colab_notebook = False\n",
    "\n",
    "data_dir = None\n",
    "aug_data_dir = None\n",
    "\n",
    "# Assign path variables\n",
    "if colab_notebook:\n",
    "    #Mount Google Drive Folder\n",
    "    from google.colab import drive\n",
    "    \n",
    "    mount_dir = '/content/drive'\n",
    "    drive.mount(mount_dir)\n",
    "    \n",
    "    data_dir = '/content/drive/My Drive/ECE 542 Final Project/data/bdd100k/seg/'\n",
    "    aug_data_dir = '/content/drive/My Drive/ECE 542 Final Project/aug_data/'\n",
    "\n",
    "    # Append local libraries\n",
    "    MASK_ROOT = os.path.abspath('/content/drive/My Drive/ECE 542 Final Project/Mask_RCNN/')\n",
    "    CIT_ROOT = os.path.abspath('/content/drive/My Drive/ECE 542 Final Project/cityscapesScripts/')\n",
    "    \n",
    "    # Create Data Directory and extract zip file\n",
    "    from os import path, mkdir\n",
    "    import subprocess\n",
    "    if not path.exists('/content/drive/My Drive/ECE 542 Final Project/data'):\n",
    "        mkdir('/content/drive/My Drive/ECE 542 Final Project/data')\n",
    "        subprocess.call(\n",
    "            [\n",
    "                'unzip', \n",
    "                '/content/drive/My Drive/ECE 542 Final Project/bdd100k_seg.zip', \n",
    "                '-d', \n",
    "                '/content/drive/My Drive/ECE 542 Final Project/data'\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "else:\n",
    "    data_dir = 'data/bdd100k/seg/'\n",
    "    aug_data_dir = 'aug_data/'\n",
    "    annotations_dir = 'data/bdd100k/labels/'\n",
    "    \n",
    "    # Append local libraries\n",
    "    MASK_ROOT = os.path.abspath('Mask_RCNN/')\n",
    "    CIT_ROOT = os.path.abspath('cityscapesScripts/')\n",
    "    \n",
    "    \n",
    "if not path.exists(aug_data_dir):\n",
    "    mkdir(aug_data_dir)\n",
    "    mkdir(aug_data_dir + 'images')\n",
    "    mkdir(aug_data_dir + 'labels')\n",
    "\n",
    "try:\n",
    "    import mcrnn\n",
    "except:\n",
    "    sys.path.append(MASK_ROOT)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    import cityscapescripts\n",
    "except:\n",
    "    sys.path.append(CIT_ROOT)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Augmentation\n",
    "This section preprocesses the data to have the correct shape and optionally augment it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 358133,
     "status": "error",
     "timestamp": 1584800571212,
     "user": {
      "displayName": "Jeffrey Barahona",
      "photoUrl": "",
      "userId": "05714273706173763154"
     },
     "user_tz": 240
    },
    "id": "86l3hfCcxfDl",
    "outputId": "47a27081-2acd-4631-d509-0c0ec9216440"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data directory is not empty\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Data Augmentation Section\n",
    "'''\n",
    "This section contains the classes and functions needed to\n",
    "augment the data for use with MaskRCNN\n",
    "'''\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "clpt = 'color_labels/train/'\n",
    "clpv = 'color_labels/val/'\n",
    "\n",
    "lpt = 'labels/train/'\n",
    "lpv = 'labels/val/'\n",
    "\n",
    "impt = 'images/train/'\n",
    "impv = 'images/val/'\n",
    "\n",
    "num_final_images = 40000 # 40K images to start\n",
    "testing = True\n",
    "\n",
    "class SegmentedDataAugmenter:\n",
    "    '''\n",
    "    Consumes 3GiB-5GiB of space while running\n",
    "    '''\n",
    "    def __init__(self, pair_list, num_images_desired, batch_size=32):\n",
    "        self.num_images = num_images_desired\n",
    "        self.raw_image_pairs = []\n",
    "        self.preprocessed_image_batch = []\n",
    "        self.file_pairs = pair_list\n",
    "        self.MaskRCNN_width = 1024\n",
    "        self.MaskRCNN_height = 1024\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Dictionary of arguments for ImageDataGenerator\n",
    "        self.augment_args = {\n",
    "            'featurewise_center': False,\n",
    "            'samplewise_center': False,\n",
    "            'featurewise_std_normalization': False,\n",
    "            'samplewise_std_normalization': False,\n",
    "            'zca_whitening': False,\n",
    "            'zca_epsilon': 1e-06,\n",
    "            'rotation_range': 0.0,\n",
    "            'width_shift_range': 0.0,\n",
    "            'height_shift_range': 0.0,\n",
    "            'brightness_range': None,\n",
    "            'shear_range': 0.0,\n",
    "            'zoom_range': 0.0,\n",
    "            'channel_shift_range': 0.0,\n",
    "            'fill_mode': 'nearest',\n",
    "            'cval': 0.0,\n",
    "            'horizontal_flip': False,\n",
    "            'vertical_flip': False,\n",
    "            'rescale': None,\n",
    "        }\n",
    "        self.augment_args = {\n",
    "            'featurewise_center': False,\n",
    "            'samplewise_center': False,\n",
    "            'featurewise_std_normalization': False,\n",
    "            'samplewise_std_normalization': False,\n",
    "            'zca_whitening': False,\n",
    "            'zca_epsilon': 1e-06,\n",
    "            'rotation_range': 120,\n",
    "            'width_shift_range': 0.2,\n",
    "            'height_shift_range': 0.2,\n",
    "            'brightness_range': None,\n",
    "            'shear_range': 0.0,\n",
    "            'zoom_range': 0.0,\n",
    "            'channel_shift_range': 0.0,\n",
    "            'fill_mode': 'nearest',\n",
    "            'cval': 0.0,\n",
    "            'horizontal_flip': True,\n",
    "            'vertical_flip': False,\n",
    "            'rescale': None,\n",
    "        }\n",
    "        \n",
    "        if num_images_desired < batch_size:\n",
    "            raise Exception('Undefined behavior with batch size larger than total number of images')\n",
    "                \n",
    "    def load_images(self):\n",
    "        # Generator function that returns list of label, image tuples 'batch_size' amount at a time\n",
    "        '''\n",
    "        Can optimize this by working a tuple of a numpy array rather than a list of image tuples and \n",
    "        combining load_images and preprocess_images. Leaving it this way in case we need access to the \n",
    "        raw images for whatever reason later.\n",
    "        \n",
    "        The generator here is used to limit the number of images in memory at a time. Once the images\n",
    "        this function yields are dereferenced, the memory is freed by Python's garbage collector.\n",
    "        '''\n",
    "        reducing_file_list = self.file_pairs\n",
    "        while self.batch_size < len(reducing_file_list):\n",
    "            self.raw_image_pairs = [] #Dereference old images\n",
    "            for label_file, image_file in reducing_file_list[:self.batch_size]:\n",
    "                label_img = cv2.imread(label_file)\n",
    "                image = cv2.imread(image_file)\n",
    "                self.raw_image_pairs.append((label_img, image))\n",
    "            reducing_file_list = reducing_file_list[self.batch_size:]\n",
    "            yield self.raw_image_pairs\n",
    "            \n",
    "        self.raw_image_pairs = [] #Dereference old images\n",
    "        for label_file, image_file in reducing_file_list[:self.batch_size]:\n",
    "            label_img = cv2.imread(label_file)\n",
    "            image = cv2.imread(image_file)\n",
    "            self.raw_image_pairs.append((label_img, image))\n",
    "        yield self.raw_image_pairs           \n",
    "        \n",
    "    def nodistort_resize_image(self, image):\n",
    "        '''\n",
    "        The idea here is to rescale the image then crop out the excess. We lose some information, but I think\n",
    "        this will give better results than scaling down the image and padding the empty vertical space\n",
    "        with zeros. We can test this if need be.\n",
    "        '''\n",
    "        goal_height = self.MaskRCNN_height\n",
    "        goal_width = self.MaskRCNN_width\n",
    "        img_shape = image.shape\n",
    "        \n",
    "        #Rescale image to eliminate all padding in final image\n",
    "        scale_factor = goal_height / img_shape[0]\n",
    "        dest_size = (int(img_shape[1] * scale_factor), int(img_shape[0] * scale_factor) )\n",
    "        resized = cv2.resize(image, dest_size)\n",
    "        \n",
    "        #Horizonally crop new image\n",
    "        img_shape = resized.shape\n",
    "        del_width = img_shape[1] - goal_width \n",
    "        resized = resized[:,int(del_width/2):int(-del_width/2),:]\n",
    "        return resized\n",
    "    \n",
    "    def preprocess_images(self):\n",
    "        # Generator function that preprocesses x number of images at a time\n",
    "        # It is done this way rather than using the preprocessor argument in ImageDataGenerator\n",
    "        # so we can have the resized data available without augmentation\n",
    "        for batch_list in self.load_images():\n",
    "            self.preprocessed_image_batch = [] #Make preprocessed image batch accessible outside of the class\n",
    "            for segmenting_pair in batch_list:\n",
    "                label = self.nodistort_resize_image(segmenting_pair[0])\n",
    "                image = self.nodistort_resize_image(segmenting_pair[1])\n",
    "                self.preprocessed_image_batch.append((label, image))\n",
    "            yield self.preprocessed_image_batch\n",
    "    \n",
    "    def process_images(self, save_dir_base=None):\n",
    "        # Generator function that augments the data in batches or saves them to files\n",
    "        \n",
    "        # Calculate the number of times to cycle image generator for each preprocessed batch\n",
    "        num_augment = int(self.num_images/len(self.file_pairs))\n",
    "        \n",
    "        if num_augment < 1:\n",
    "            raise Exception('Too few images requested')\n",
    "\n",
    "        for image_batch in self.preprocess_images():\n",
    "            labels, images = map(list, zip(*image_batch))\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            images = np.array(images)\n",
    "            labels = np.array(labels)\n",
    "            \n",
    "            # Use ImageDataGenerator to augment batch\n",
    "            label_augment = ImageDataGenerator(**self.augment_args)\n",
    "            image_augment = ImageDataGenerator(**self.augment_args)\n",
    "            \n",
    "            \n",
    "            # We need to ensure that the seeds are the same so that the same transformations are applied\n",
    "            seed = random.randint(0,65000)\n",
    "            '''\n",
    "            This is set up to generate a set number of augmented images for each batch of raw images such that raw images are\n",
    "            equally represented in the augmented image data set\n",
    "            '''\n",
    "            aug_label_gen = label_augment.flow(x=labels, batch_size=self.batch_size, seed=seed) \n",
    "            aug_img_gen = image_augment.flow(x=images, batch_size=self.batch_size, seed=seed)\n",
    "            \n",
    "            for i in range(0, num_augment):\n",
    "                label_batch = next(aug_label_gen)\n",
    "                image_batch = next(aug_img_gen)\n",
    "                yield (label_batch, image_batch)\n",
    "\n",
    "def save_preprocessed_to_directory():\n",
    "    pass\n",
    "\n",
    "def save_augmented_to_directory(num_augmented_images):\n",
    "    \n",
    "    # Check if augmented data directory is empty\n",
    "    # Assume correct subdirectories were made\n",
    "    for dirpath, dirnames, filenames in walk(aug_data_dir):\n",
    "        if filenames:\n",
    "            raise Exception(\"Augmented data directory is not empty\")\n",
    "\n",
    "\n",
    "    # Generate File Lists from Training Directory\n",
    "    color_labels_train = [ data_dir + clpt + cl for cl in listdir(data_dir + clpt) if isfile(join(data_dir + clpt, cl)) ] \n",
    "    images_train = [ data_dir + impt + img for img in listdir(data_dir + impt) if isfile(join(data_dir + impt, img)) ]\n",
    "\n",
    "    # Images with label map pair have the same file prefix\n",
    "    color_labels_train.sort()\n",
    "    images_train.sort()\n",
    "\n",
    "    data_pairs = list(zip(color_labels_train, images_train))\n",
    "    image_augment = SegmentedDataAugmenter(data_pairs, num_augmented_images) \n",
    "    augmented_data_generator  = image_augment.process_images()\n",
    "    \n",
    "    label_path = aug_data_dir + 'labels/'\n",
    "    image_path = aug_data_dir + 'images/'\n",
    "    index = 0\n",
    "    \n",
    "    for label_batch, image_batch in augmented_data_generator:\n",
    "        #Assume these tensors have the same shape\n",
    "        for i in range(0,image_batch.shape[0]):\n",
    "            label_file_name = label_path + 'label-' + str(index) + '.png'\n",
    "            image_file_name = image_path + 'image-' + str(index) + '.png'\n",
    "            index+=1\n",
    "            \n",
    "            Image.fromarray(image_batch[i].astype(np.uint8)).save(image_file_name)\n",
    "            Image.fromarray(label_batch[i].astype(np.uint8)).save(label_file_name)\n",
    "        # We need aggressive garbage collecting to keep from using all the memory\n",
    "        gc.collect() # clean up after every batch\n",
    "\n",
    "# Save augmented data\n",
    "try:\n",
    "    save_augmented_to_directory(10240)\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "finally:\n",
    "    gc.collect() # This should get rid of the dereferenced objects in the function\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Mask Extraction\n",
    "This section focuses on converting semantic segmentation labels into instance masks and storing them in a usable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6c3f83310>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instance Mask Extraction\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import random\n",
    "    \n",
    "from mrcnn.utils import Dataset\n",
    "from cityscapesscripts.helpers.csHelpers import getCoreImageFileName\n",
    "\n",
    "class CityscapesSegmentationDataset(Dataset):\n",
    "    \n",
    "    def load_cityscapes(self, root_directory, subset):\n",
    "        if subset == 'train':\n",
    "            self.data_dir = os.path.join(root_directory, 'train')\n",
    "        elif subset == 'val':\n",
    "            self.data_dir = os.path.join(root_directory, 'val')\n",
    "        elif subset == 'test':\n",
    "            self.data_dir = os.path.join(root_directory, 'test')\n",
    "        else:\n",
    "            raise Exception('No valid subset provided')\n",
    "        \n",
    "        # Create dictionary to house all files according to their image_id\n",
    "        image_id_set = set()\n",
    "        for root, dirs, filenames in os.walk(self.data_dir):\n",
    "             for filename in filenames:\n",
    "                image_id_set.add(getCoreImageFileName(filename))\n",
    "        \n",
    "        self._image_ids = list(image_id_set)\n",
    "        #TODO Move remainder of annotation information to Dataset Class\n",
    "        \n",
    "    def load_mask(self, image_id):\n",
    "        '''\n",
    "        Loads mask corresponding to an image id\n",
    "        \n",
    "        image_id: the unique id of the form city_sequenceNb_frame_Nb\n",
    "        \n",
    "        returns a bool array of masks and a list of class ids\n",
    "        The polygons are extracted from the json files and constructed into a binary image\n",
    "        using PIL. \n",
    "        '''\n",
    "        \n",
    "        city = image_id.split('_')[0] # First element in list should be city\n",
    "        annotation_path = os.path.join(os.path.join(self.data_dir, city), image_id + '_gtFine_polygons.json')\n",
    "        ann_dict = {}\n",
    "        \n",
    "        with open(annotation_path) as annotation:\n",
    "            ann_dict = json.load(annotation)\n",
    "        masks = []\n",
    "        class_ids = []\n",
    "        \n",
    "        for obj in ann_dict['objects']:\n",
    "            class_ids.append(obj['label'])\n",
    "            mask = Image.new(mode = '1', size = (ann_dict['imgWidth'], ann_dict['imgHeight']))\n",
    "            draw = ImageDraw.Draw(mask)\n",
    "            \n",
    "            try:\n",
    "                points = obj['polygon']\n",
    "            except:\n",
    "                print('no polygons for {}'.format(obj['label']))\n",
    "            \n",
    "            # PIL expects a tuple of tuples for points\n",
    "            points = [tuple(coords) for coords in points]\n",
    "            points = tuple(points)\n",
    "            \n",
    "            draw.polygon((points), fill=1)\n",
    "            masks.append(mask)\n",
    "        \n",
    "        masks = np.stack(masks)\n",
    "        return masks, class_ids\n",
    "            \n",
    "# Testing\n",
    "csds = CityscapesSegmentationDataset()\n",
    "csds.load_cityscapes('data/gtFine/', 'val')\n",
    "masks, class_ids = csds.load_mask('frankfurt_000000_000294')\n",
    "num_instances = len(class_ids)\n",
    "select = random.randint(0,num_instances - 1)\n",
    "\n",
    "print(class_ids[select])\n",
    "fig=plt.figure(figsize=(9, 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.imshow(np.asarray(masks[select]), cmap=plt.cm.gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ECE542FinalProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ece542projects",
   "language": "python",
   "name": "ece542projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
