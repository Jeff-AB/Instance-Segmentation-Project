{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Jeff-AB/ECE542FinalProject/blob/jeff-development/ECE542FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNtCvd6KxZO0"
   },
   "source": [
    "# ECE 542 Final Project\n",
    "\n",
    "## How to Develop Code for the ECE 542 Final Project\n",
    "We will be using jupyter notebooks and Google Codelabs to develop our image segmentation application. Each user will work from the same notebook using branches. Here is our strategy to use branches.\n",
    "\n",
    "1.   Create a public github account(not a NCSU account). Request an invite to the repository from Jeff, and you will receive an email at the account linked to your github with an access link.\n",
    "\n",
    "2.   Perform the following command to create a local repository on your computer\n",
    "\n",
    "## Upload Rules\n",
    "Upload your changes to your branch only. When you think that your changes are sufficient, make a pull request to the master branch from your personal branch and assign other members to review it. After a branch has been merged, everyone has to update their setups with the new master branch. You will be notified of this in the slack channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "hscjYpi8cktA",
    "outputId": "32b1783f-5fa7-42c0-c3c8-d14168b6a70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Google Colab or Local Notebook Settings\n",
    "colab_notebook = True\n",
    "\n",
    "data_dir = None\n",
    "aug_data_dir = None\n",
    "\n",
    "# Assign path variables\n",
    "if colab_notebook:\n",
    "    #Mount Google Drive Folder\n",
    "    from google.colab import drive\n",
    "    \n",
    "    mount_dir = '/content/drive'\n",
    "    drive.mount(mount_dir)\n",
    "    \n",
    "    data_dir = '/content/drive/My Drive/ECE 542 Final Project/data/bdd100k/seg/'\n",
    "    aug_data_dir = '/content/drive/My Drive/ECE 542 Final Project/aug_data/'\n",
    "    \n",
    "    # Create Data Directory and extract zip file\n",
    "    from os import path, mkdir\n",
    "    import subprocess\n",
    "    if not path.exists('/content/drive/My Drive/ECE 542 Final Project/data'):\n",
    "        mkdir('/content/drive/My Drive/ECE 542 Final Project/data')\n",
    "        subprocess.call(\n",
    "            [\n",
    "                'unzip', \n",
    "                '/content/drive/My Drive/ECE 542 Final Project/bdd100k_seg.zip', \n",
    "                '-d', \n",
    "                '/content/drive/My Drive/ECE 542 Final Project/data'\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "else:\n",
    "    data_dir = 'data/bdd100k/seg/'\n",
    "    aug_data_dir = 'aug_data/'\n",
    "    \n",
    "if not path.exists(aug_data_dir):\n",
    "    mkdir(aug_data_dir)\n",
    "    mkdir(aug_data_dir + 'images')\n",
    "    mkdir(aug_data_dir + 'labels')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "id": "86l3hfCcxfDl",
    "outputId": "99e5bdb1-7036-4c01-a159-793bead06448"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7f08a31b6bf8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/_weakrefset.py\", line 38, in _remove\n",
      "    def _remove(item, selfref=ref(self)):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8564eed39f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;31m# Save augmented data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0msave_augmented_to_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8564eed39f2d>\u001b[0m in \u001b[0;36msave_augmented_to_directory\u001b[0;34m(num_augmented_images)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# We need aggressive garbage collecting to keep from using all the memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"eXIf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m     \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IDAT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36mputchunk\u001b[0;34m(fp, cid, *data)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m     \u001b[0mcrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_crc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_crc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Data Augmentation Section\n",
    "'''\n",
    "This section contains the classes and functions needed to\n",
    "augment the data for use with MaskRCNN\n",
    "'''\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "clpt = 'color_labels/train/'\n",
    "clpv = 'color_labels/val/'\n",
    "\n",
    "impt = 'images/train/'\n",
    "impv = 'images/val/'\n",
    "\n",
    "num_final_images = 40000 # 40K images to start\n",
    "testing = True\n",
    "\n",
    "class SegmentedDataAugmenter:\n",
    "    '''\n",
    "    Consumes 3GiB-5GiB of space while running\n",
    "    '''\n",
    "    def __init__(self, pair_list, num_images_desired, batch_size=32):\n",
    "        self.num_images = num_images_desired\n",
    "        self.raw_image_pairs = []\n",
    "        self.preprocessed_image_batch = []\n",
    "        self.file_pairs = pair_list\n",
    "        self.MaskRCNN_width = 1024\n",
    "        self.MaskRCNN_height = 1024\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Dictionary of arguments for ImageDataGenerator\n",
    "        self.augment_args = {\n",
    "            'featurewise_center': False,\n",
    "            'samplewise_center': False,\n",
    "            'featurewise_std_normalization': False,\n",
    "            'samplewise_std_normalization': False,\n",
    "            'zca_whitening': False,\n",
    "            'zca_epsilon': 1e-06,\n",
    "            'rotation_range': 0.0,\n",
    "            'width_shift_range': 0.0,\n",
    "            'height_shift_range': 0.0,\n",
    "            'brightness_range': None,\n",
    "            'shear_range': 0.0,\n",
    "            'zoom_range': 0.0,\n",
    "            'channel_shift_range': 0.0,\n",
    "            'fill_mode': 'nearest',\n",
    "            'cval': 0.0,\n",
    "            'horizontal_flip': False,\n",
    "            'vertical_flip': False,\n",
    "            'rescale': None,\n",
    "        }\n",
    "        self.augment_args = {\n",
    "            'featurewise_center': False,\n",
    "            'samplewise_center': False,\n",
    "            'featurewise_std_normalization': False,\n",
    "            'samplewise_std_normalization': False,\n",
    "            'zca_whitening': False,\n",
    "            'zca_epsilon': 1e-06,\n",
    "            'rotation_range': 120,\n",
    "            'width_shift_range': 0.2,\n",
    "            'height_shift_range': 0.2,\n",
    "            'brightness_range': None,\n",
    "            'shear_range': 0.0,\n",
    "            'zoom_range': 0.0,\n",
    "            'channel_shift_range': 0.0,\n",
    "            'fill_mode': 'nearest',\n",
    "            'cval': 0.0,\n",
    "            'horizontal_flip': True,\n",
    "            'vertical_flip': False,\n",
    "            'rescale': None,\n",
    "        }\n",
    "        \n",
    "        if num_images_desired < batch_size:\n",
    "            raise Exception('Undefined behavior with batch size larger than total number of images')\n",
    "                \n",
    "    def load_images(self):\n",
    "        # Generator function that returns list of label, image tuples 'batch_size' amount at a time\n",
    "        '''\n",
    "        Can optimize this by working a tuple of a numpy array rather than a list of image tuples and \n",
    "        combining load_images and preprocess_images. Leaving it this way in case we need access to the \n",
    "        raw images for whatever reason later.\n",
    "        \n",
    "        The generator here is used to limit the number of images in memory at a time. Once the images\n",
    "        this function yields are dereferenced, the memory is freed by Python's garbage collector.\n",
    "        '''\n",
    "        reducing_file_list = self.file_pairs\n",
    "        while self.batch_size < len(reducing_file_list):\n",
    "            self.raw_image_pairs = [] #Dereference old images\n",
    "            for label_file, image_file in reducing_file_list[:self.batch_size]:\n",
    "                label_img = cv2.imread(label_file)\n",
    "                image = cv2.imread(image_file)\n",
    "                self.raw_image_pairs.append((label_img, image))\n",
    "            reducing_file_list = reducing_file_list[self.batch_size:]\n",
    "            yield self.raw_image_pairs\n",
    "            \n",
    "        self.raw_image_pairs = [] #Dereference old images\n",
    "        for label_file, image_file in reducing_file_list[:self.batch_size]:\n",
    "            label_img = cv2.imread(label_file)\n",
    "            image = cv2.imread(image_file)\n",
    "            self.raw_image_pairs.append((label_img, image))\n",
    "        yield self.raw_image_pairs           \n",
    "        \n",
    "    def nodistort_resize_image(self, image):\n",
    "        '''\n",
    "        The idea here is to rescale the image then crop out the excess. We lose some information, but I think\n",
    "        this will give better results than scaling down the image and padding the empty vertical space\n",
    "        with zeros. We can test this if need be.\n",
    "        '''\n",
    "        goal_height = self.MaskRCNN_height\n",
    "        goal_width = self.MaskRCNN_width\n",
    "        img_shape = image.shape\n",
    "        \n",
    "        #Rescale image to eliminate all padding in final image\n",
    "        scale_factor = goal_height / img_shape[0]\n",
    "        dest_size = (int(img_shape[1] * scale_factor), int(img_shape[0] * scale_factor) )\n",
    "        resized = cv2.resize(image, dest_size)\n",
    "        \n",
    "        #Horizonally crop new image\n",
    "        img_shape = resized.shape\n",
    "        del_width = img_shape[1] - goal_width \n",
    "        resized = resized[:,int(del_width/2):int(-del_width/2),:]\n",
    "        return resized\n",
    "    \n",
    "    def preprocess_images(self):\n",
    "        # Generator function that preprocesses x number of images at a time\n",
    "        # It is done this way rather than using the preprocessor argument in ImageDataGenerator\n",
    "        # so we can have the resized data available without augmentation\n",
    "        for batch_list in self.load_images():\n",
    "            self.preprocessed_image_batch = [] #Make preprocessed image batch accessible outside of the class\n",
    "            for segmenting_pair in batch_list:\n",
    "                label = self.nodistort_resize_image(segmenting_pair[0])\n",
    "                image = self.nodistort_resize_image(segmenting_pair[1])\n",
    "                self.preprocessed_image_batch.append((label, image))\n",
    "            yield self.preprocessed_image_batch\n",
    "    \n",
    "    def process_images(self, save_dir_base=None):\n",
    "        # Generator function that augments the data in batches or saves them to files\n",
    "        \n",
    "        for image_batch in self.preprocess_images():\n",
    "            labels, images = map(list, zip(*image_batch))\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            images = np.array(images)\n",
    "            labels = np.array(labels)\n",
    "            \n",
    "            # Use ImageDataGenerator to augment batch\n",
    "            label_augment = ImageDataGenerator(**self.augment_args)\n",
    "            image_augment = ImageDataGenerator(**self.augment_args)\n",
    "            \n",
    "            # Calculate the number of images needed for each raw image batch\n",
    "            num_augment = int(self.num_images/len(self.file_pairs))\n",
    "            if num_augment < len(self.file_pairs):\n",
    "                raise Exception('Too few images requested')\n",
    "            \n",
    "            # We need to ensure that the seeds are the same so that the same transformations are applied\n",
    "            seed = random.randint(0,65000)\n",
    "            '''\n",
    "            This is set up to generate a set number of augmented images for each batch of raw images such that raw images are\n",
    "            equally represented in the augmented image data set\n",
    "            '''\n",
    "            aug_label_gen = label_augment.flow(x=labels, batch_size=self.batch_size, seed=seed) \n",
    "            aug_img_gen = image_augment.flow(x=images, batch_size=self.batch_size, seed=seed)\n",
    "            \n",
    "            print(num_augment)\n",
    "            for i in range(0, num_augment, self.batch_size):\n",
    "                label_batch = next(aug_label_gen)\n",
    "                image_batch = next(aug_img_gen)\n",
    "                yield (label_batch, image_batch)\n",
    "\n",
    "def save_preprocessed_to_directory():\n",
    "    pass\n",
    "\n",
    "def save_augmented_to_directory(num_augmented_images):\n",
    "    \n",
    "    # Check if augmented data directory is empty\n",
    "    # Assume correct subdirectories were made\n",
    "    for dirpath, dirnames, filenames in walk(aug_data_dir):\n",
    "        if filenames:\n",
    "            raise Exception(\"Augmented data directory is not empty\")\n",
    "\n",
    "\n",
    "    # Generate File Lists from Training Directory\n",
    "    color_labels_train = [ data_dir + clpt + cl for cl in listdir(data_dir + clpt) if isfile(join(data_dir + clpt, cl)) ] \n",
    "    images_train = [ data_dir + impt + img for img in listdir(data_dir + impt) if isfile(join(data_dir + impt, img)) ]\n",
    "\n",
    "    # Images with label map pair have the same file prefix\n",
    "    color_labels_train.sort()\n",
    "    images_train.sort()\n",
    "\n",
    "    data_pairs = list(zip(color_labels_train, images_train))\n",
    "    image_augment = SegmentedDataAugmenter(data_pairs, num_augmented_images) \n",
    "    augmented_data_generator  = image_augment.process_images()\n",
    "    \n",
    "    label_path = aug_data_dir + 'labels/'\n",
    "    image_path = aug_data_dir + 'images/'\n",
    "    index = 0\n",
    "    \n",
    "    for label_batch, image_batch in augmented_data_generator:\n",
    "        #Assume these tensors have the same shape\n",
    "        for i in range(0,image_batch.shape[0]):\n",
    "            label_file_name = label_path + 'label-' + str(index) + '.png'\n",
    "            image_file_name = image_path + 'image-' + str(index) + '.png'\n",
    "            index+=1\n",
    "            \n",
    "            Image.fromarray(image_batch[i].astype(np.uint8)).save(image_file_name)\n",
    "            Image.fromarray(label_batch[i].astype(np.uint8)).save(label_file_name)\n",
    "        # We need aggressive garbage collecting to keep from using all the memory\n",
    "        gc.collect() # clean up after every batch\n",
    "\n",
    "# Save augmented data\n",
    "try:\n",
    "    save_augmented_to_directory(10240)\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "finally:\n",
    "    gc.collect() # This should get rid of the dereferenced objects in the function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CM848jWCckta",
    "outputId": "2e7e9463-5d22-42e9-ef9e-75271a6a2671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\tlabels\n"
     ]
    }
   ],
   "source": [
    "! ls '/content/drive/My Drive/ECE 542 Final Project/aug_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50DXsViZckth"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ECE542FinalProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ece542projects",
   "language": "python",
   "name": "ece542projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
